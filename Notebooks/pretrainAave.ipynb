{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04e9366-1885-4d8d-b0d0-ede0fd865ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greena12/.conda/envs/greena12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from os import makedirs\n",
    "from os.path import join, basename\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from arguments import define_new_main_parser\n",
    "import json\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from models.modules import TabFormerBertLM, TabFormerBertForClassification, TabFormerBertModel, TabStaticFormerBert, \\\n",
    "    TabStaticFormerBertLM, TabStaticFormerBertClassification\n",
    "from misc.utils import ordered_split_dataset, compute_cls_metrics\n",
    "from dataset.datacollator import *\n",
    "from main import main\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71d25b3-2692-45ce-a47e-40eb56554314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 18:19:05,241 - root - INFO - Logging setup completed.\n"
     ]
    }
   ],
   "source": [
    "def setup_logging(output_dir=\"logs\", log_file_name='output.log'):\n",
    "    log_dir = join(output_dir, \"logs\")\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    makedirs(log_dir, exist_ok=True)\n",
    "    log_file = join(log_dir, log_file_name)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    fhandler = logging.FileHandler(log_file)\n",
    "    fhandler.setLevel(logging.DEBUG)\n",
    "\n",
    "    chandler = logging.StreamHandler()\n",
    "    chandler.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    chandler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.addHandler(chandler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logging(output_dir=\"logs\")\n",
    "\n",
    "\n",
    "logger.info(\"Logging setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36069bb4-c991-412d-adb9-12c6470427f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_user_features = True\n",
    "include_time_features = True\n",
    "include_market_features = False\n",
    "include_exo_features = False\n",
    "\n",
    "feature_extension = \"\"\n",
    "if include_user_features:\n",
    "    feature_extension += \"_user\"\n",
    "if include_market_features:\n",
    "    feature_extension += \"_market\"\n",
    "if include_time_features:\n",
    "    feature_extension += \"_time\"\n",
    "if include_exo_features:\n",
    "    feature_extension += \"_exoLagged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22c9d91-648d-4bc4-8f95-2d9acddae6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"/data/IDEA_DeFi_Research/Data/AML/LI_Small/preprocessed\" \n",
    "dt=\"aml\"\n",
    "exp_name=\"debug\"\n",
    "time_pos_type=\"regular_position\"\n",
    "fname = f\"transactions{feature_extension}_train\"  \n",
    "val_fname = f\"transactions{feature_extension}_val\" \n",
    "test_fname = f\"transactions{feature_extension}_test\"  \n",
    "fextension = False\n",
    "bs=32\n",
    "field_hs = 64 # hidden state dimension of the fields in the transformer (default: 768)\n",
    "seq_len = 25 # length for transaction sliding window\n",
    "stride = 5 # stride for transaction sliding window\n",
    "num_train_epochs=5\n",
    "save_steps=5000\n",
    "eval_steps=5000\n",
    "external_val=False\n",
    "output_dir=f\"{data}/output/{exp_name}\"\n",
    "checkpoint=None\n",
    "nrows=2000000\n",
    "vocab_dir=f\"{data}/vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d9a57b-0dd5-4b64-ac65-5e189091bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_str = f\"--do_train \\\n",
    "    --mlm \\\n",
    "    --pad_seq_first \\\n",
    "    --get_rids \\\n",
    "    --field_ce \\\n",
    "    --lm_type bert \\\n",
    "    --field_hs {field_hs} \\\n",
    "    --data_type {dt} \\\n",
    "    --seq_len {seq_len} \\\n",
    "    --stride {stride} \\\n",
    "    --num_train_epochs {num_train_epochs} \\\n",
    "    --data_root {data}/ \\\n",
    "    --train_batch_size {bs} \\\n",
    "    --eval_batch_size {bs} \\\n",
    "    --save_steps {save_steps} \\\n",
    "    --eval_steps {eval_steps} \\\n",
    "    --data_fname {fname} \\\n",
    "    --data_val_fname {val_fname} \\\n",
    "    --data_test_fname {test_fname} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --time_pos_type {time_pos_type} \\\n",
    "    --vocab_dir {vocab_dir} \\\n",
    "    --nrows {nrows} \\\n",
    "    --vocab_cached \\\n",
    "    --encoder_cached \\\n",
    "    --cached \\\n",
    "    \"\n",
    "   # \n",
    "if fextension:\n",
    "    arg_str += f\"--fextension {fextension} \\\n",
    "    --external_vocab_path {data}/vocab_ob_{fextension}\"\n",
    "else:\n",
    "    arg_str += f\"--external_vocab_path {data}/vocab/vocab_ob\"\n",
    "if external_val:\n",
    "    arg_str += f\"\\\n",
    "    --external_val\"\n",
    "if checkpoint is not None:\n",
    "    arg_str += f\"\\\n",
    "    --checkpoint {checkpoint}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06320fe2-d4bf-41ff-ba54-1223c6f77d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = define_new_main_parser()\n",
    "opts = parser.parse_args(arg_str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a79b5-cb02-4b9e-9636-2388d9ede926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 18:19:05,289 - dataset.basic - INFO - cached encoded data is read from transactions_user_time_train.encoded.csv\n",
      "2025-02-07 18:19:08,028 - dataset.basic - INFO - read data : (2000000, 48)\n",
      "2025-02-07 18:19:08,030 - dataset.basic - INFO - using cached vocab from /data/IDEA_DeFi_Research/Data/eCommerce/Cosmetics/preprocessed/vocab/vocab_ob\n",
      "2025-02-07 18:19:08,100 - dataset.dataset - INFO - preparing user level data...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146723/146723 [01:06<00:00, 2215.09it/s]\n",
      "2025-02-07 18:20:18,469 - dataset.dataset - INFO - creating transaction samples with vocab\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146723/146723 [00:56<00:00, 2598.56it/s]\n",
      "2025-02-07 18:21:14,941 - dataset.dataset - INFO - ncols: 45\n",
      "2025-02-07 18:21:14,941 - dataset.dataset - INFO - no of samples 488990\n",
      "2025-02-07 18:21:15,493 - main - INFO - vocab size: 645\n",
      "2025-02-07 18:21:15,497 - main - INFO - dataset size: 488990\n",
      "2025-02-07 18:21:15,540 - dataset.basic - INFO - cached encoded data is read from transactions_user_time_train.encoded.csv\n",
      "2025-02-07 18:21:18,024 - dataset.basic - INFO - read data : (2000000, 48)\n",
      "2025-02-07 18:21:18,026 - dataset.basic - INFO - using cached vocab from /data/IDEA_DeFi_Research/Data/eCommerce/Cosmetics/preprocessed/vocab/vocab_ob\n",
      "2025-02-07 18:21:18,106 - dataset.dataset - INFO - preparing user level data...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146723/146723 [01:06<00:00, 2207.19it/s]\n",
      "2025-02-07 18:22:29,135 - dataset.dataset - INFO - creating transaction samples with vocab\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146723/146723 [01:00<00:00, 2414.66it/s]\n",
      "2025-02-07 18:23:29,901 - dataset.dataset - INFO - ncols: 45\n",
      "2025-02-07 18:23:29,902 - dataset.dataset - INFO - no of samples 488990\n",
      "2025-02-07 18:23:30,493 - main - INFO - test dataset size: 488990\n",
      "2025-02-07 18:23:30,504 - main - INFO - # Using external test dataset, lengths: train [410751]  valid [78239]  test [488990]\n",
      "2025-02-07 18:23:30,505 - main - INFO - # lengths: train [0.42]  valid [0.08]  test [0.50]\n",
      "/home/greena12/.conda/envs/greena12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "2025-02-07 18:23:35,884 - main - INFO - model initiated: <class 'models.modules.TabFormerHierarchicalLM'>\n",
      "2025-02-07 18:23:35,887 - main - INFO - Total parameters: 622716805\n",
      "2025-02-07 18:23:35,888 - main - INFO - Trainable parameters: 622716805\n",
      "2025-02-07 18:23:35,888 - main - INFO - collator class: TransDataCollatorForLanguageModeling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5335' max='64180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5335/64180 35:45 < 6:34:32, 2.49 it/s, Epoch 0.42/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>43.760100</td>\n",
       "      <td>44.326366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opts.log_dir = join(opts.output_dir, \"logs\")\n",
    "makedirs(opts.output_dir, exist_ok=True)\n",
    "makedirs(opts.log_dir, exist_ok=True)\n",
    "\n",
    "opts.cls_exp_task = opts.cls_task or opts.export_task\n",
    "\n",
    "if (not opts.mlm) and (not opts.cls_exp_task) and opts.lm_type == \"bert\":\n",
    "    raise Exception(\n",
    "        \"Error: Bert needs either '--mlm', '--cls_task' or '--export_task' option. Please re-run with this flag \"\n",
    "        \"included.\")\n",
    "\n",
    "main(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a833476-ea5c-408d-84f3-711296f21715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (greena12)",
   "language": "python",
   "name": "greena12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
