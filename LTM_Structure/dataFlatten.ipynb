{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d374638a-18ac-4ecc-84d3-bf3c7d3adfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pyreadr\n",
    "import os\n",
    "from os.path import join, basename\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from arguments import parse_arguments\n",
    "from exp_components.utils import get_data_path\n",
    "\n",
    "def get_previous_transactions_for_target(transactions, target_type, transaction_id_column='id', user_column='user', timestamp_column='timestamp', max_previous=9):\n",
    "    \"\"\"\n",
    "    For each current transaction (i.e. with type == target_type), obtain the current transaction and up to max_previous\n",
    "    transactions (of all types) from the same user that occurred before it.\n",
    "    \n",
    "    Parameters:\n",
    "    - transactions: DataFrame containing all transaction data.\n",
    "    - target_type: The target type for current transactions (e.g. \"borrow\").\n",
    "    - transaction_id_column: Name of the transaction ID column (default 'id').\n",
    "    - user_column: Name of the user ID column (default 'user').\n",
    "    - timestamp_column: Name of the timestamp column (default 'timestamp').\n",
    "    - max_previous: Maximum number of previous transactions to retrieve (default 9).\n",
    "    \n",
    "    Returns:\n",
    "    - A list of tuples, each containing (current transaction Series, DataFrame of previous transactions)\n",
    "      where the current transaction has type == target_type.\n",
    "    \"\"\"\n",
    "    # Sort all transactions by user and timestamp\n",
    "    transactions_sorted = transactions.sort_values(by=[user_column, timestamp_column]).reset_index(drop=True)\n",
    "    \n",
    "    previous_transactions = []\n",
    "    # Only iterate over transactions that are of the target type (as current transaction)\n",
    "    for idx, row in transactions_sorted.iterrows():\n",
    "        if row.get(\"type\") != target_type:\n",
    "            continue\n",
    "        current_transaction = row\n",
    "        user = row[user_column]\n",
    "        current_timestamp = row[timestamp_column]\n",
    "        # Get transactions for the same user with timestamp less than current_timestamp (all types)\n",
    "        previous = transactions_sorted[\n",
    "            (transactions_sorted[user_column] == user) & \n",
    "            (transactions_sorted[timestamp_column] < current_timestamp)\n",
    "        ].sort_values(by=timestamp_column, ascending=False).head(max_previous)\n",
    "        previous_transactions.append((current_transaction, previous))\n",
    "    \n",
    "    return previous_transactions\n",
    "\n",
    "def flatten_previous_transactions(previous_transactions, transaction_id_column='id', user_column='user', max_previous=9):\n",
    "    \"\"\"\n",
    "    Flatten each current transaction (with its previous transactions) into a single row,\n",
    "    placing the user in the first column.\n",
    "    \n",
    "    Parameters:\n",
    "    - previous_transactions: List returned from get_previous_transactions_for_target.\n",
    "    - transaction_id_column: Name of the transaction ID column (default 'id').\n",
    "    - user_column: Name of the user ID column (default 'user').\n",
    "    - max_previous: Maximum number of previous transactions to retrieve (default 9).\n",
    "    \n",
    "    Returns:\n",
    "    - A flattened DataFrame with each row corresponding to a current transaction.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    for current, previous in previous_transactions:\n",
    "        row = {user_column: current[user_column], transaction_id_column: current[transaction_id_column]}\n",
    "        # Add features from the current transaction\n",
    "        for col in current.index:\n",
    "            if col not in [transaction_id_column, user_column, 'timestamp']:\n",
    "                row[f\"{col}_current\"] = current[col]\n",
    "        # Add features from the previous transactions\n",
    "        for i in range(max_previous):\n",
    "            if i < len(previous):\n",
    "                prev_transaction = previous.iloc[i]\n",
    "                for col in prev_transaction.index:\n",
    "                    if col not in [transaction_id_column, user_column, 'timestamp']:\n",
    "                        row[f\"{col}_previous_{i+1}\"] = prev_transaction[col]\n",
    "            else:\n",
    "                # If there are fewer than max_previous transactions, fill with NaN\n",
    "                for col in current.index:\n",
    "                    if col not in [transaction_id_column, user_column, 'timestamp']:\n",
    "                        row[f\"{col}_previous_{i+1}\"] = np.nan\n",
    "        flattened_data.append(row)\n",
    "    \n",
    "    flattened_df = pd.DataFrame(flattened_data)\n",
    "    \n",
    "    # Reorder columns to place the user column first\n",
    "    cols = [user_column, transaction_id_column] + [col for col in flattened_df.columns if col not in [user_column, transaction_id_column]]\n",
    "    flattened_df = flattened_df[cols]\n",
    "    \n",
    "    return flattened_df\n",
    "\n",
    "def preprocess_flattened_data_s(flattened_data, train_data=None, max_previous=9):\n",
    "    \"\"\"\n",
    "    Preprocess the flattened data.\n",
    "    \n",
    "    Parameters:\n",
    "    - flattened_data: Flattened DataFrame.\n",
    "    - train_data: (Optional) training data used for aligning categorical features.\n",
    "    - max_previous: Maximum number of previous transactions (default 9).\n",
    "    \n",
    "    Returns:\n",
    "    - A preprocessed DataFrame with all missing values replaced by -1.\n",
    "    \"\"\"\n",
    "    # Drop unnecessary columns (e.g., historical 'timestamp' columns)\n",
    "    features_to_drop = ['timestamp']\n",
    "    transaction_columns_to_drop = [\n",
    "        f\"{feature}_previous_{i}\" for feature in features_to_drop for i in range(1, max_previous + 1)\n",
    "    ] + [f\"{feature}_current\" for feature in features_to_drop]\n",
    "    \n",
    "    flattened_data = flattened_data.drop(\n",
    "        columns=[col for col in transaction_columns_to_drop if col in flattened_data.columns]\n",
    "    )\n",
    "    \n",
    "    # Convert object type columns to category type\n",
    "    for col in flattened_data.select_dtypes(include=['object']).columns:\n",
    "        flattened_data[col] = flattened_data[col].astype('category')\n",
    "    \n",
    "    # If training data is provided, align the categorical features\n",
    "    if train_data is not None:\n",
    "        categorical_features = flattened_data.select_dtypes(include=['category']).columns\n",
    "        for feature in categorical_features:\n",
    "            flattened_data[feature] = pd.Categorical(\n",
    "                flattened_data[feature], categories=train_data[feature].cat.categories\n",
    "            )\n",
    "    \n",
    "    # Fill all missing values with -1.\n",
    "    # For categorical columns, add -1 to categories before filling if necessary.\n",
    "    for col in flattened_data.columns:\n",
    "        if flattened_data[col].dtype.name == 'category':\n",
    "            if -1 not in flattened_data[col].cat.categories:\n",
    "                flattened_data[col] = flattened_data[col].cat.add_categories([-1])\n",
    "            flattened_data[col] = flattened_data[col].fillna(-1)\n",
    "        else:\n",
    "            flattened_data[col] = flattened_data[col].fillna(-1)\n",
    "    \n",
    "    return flattened_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa114708-5236-40af-b617-860c4e455ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transaction data, total rows: 1977491)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Main Program --------------------\n",
    "\n",
    "\n",
    "target_type = \"repay\"\n",
    "\n",
    "# transactions = pyreadr.read_r(f\"{data_path}transactions{feature_extension}.rds\")[None]\n",
    "transactions = pyreadr.read_r(\"/data/IDEA_DeFi_Research/Data/Lending_Protocols/Aave/V2/Mainnet/transactions_user_market_time.rds\")[None]\n",
    "print(f\"Loaded transaction data, total rows: {transactions.shape[0]})\")\n",
    "\n",
    "transactions = transactions.loc[:, ~transactions.columns.str.contains('exo')]\n",
    "transactions = transactions[transactions['type'] != 'collateral']\n",
    "\n",
    "transactions['timestamp'] = pd.to_datetime(transactions['timestamp'].astype(float), unit='s', origin='1970-01-01')\n",
    "\n",
    "previous_transactions = get_previous_transactions_for_target(transactions, target_type=target_type)\n",
    "\n",
    "flattened_df = flatten_previous_transactions(previous_transactions)\n",
    "\n",
    "processed_data = preprocess_flattened_data_s(flattened_df)\n",
    "\n",
    "train_data, test_data = train_test_split(processed_data, test_size=0.2, random_state=42)\n",
    "\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_path_rds = os.path.join(output_dir, f\"train_{target_type}.rds\")\n",
    "test_path_rds = os.path.join(output_dir, f\"test_{target_type}.rds\")\n",
    "\n",
    "pyreadr.write_rds(train_path_rds, train_data)\n",
    "pyreadr.write_rds(test_path_rds, test_data)\n",
    "\n",
    "print(f\"Training data for type '{target_type}' saved to: {train_path_rds}\")\n",
    "print(f\"Test data for type '{target_type}' saved to: {test_path_rds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b729f0-23a3-45cf-ae70-74de24901a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1517812/3566275334.py:2: DtypeWarning: Columns (138,140,144,145,152,250,264,266,270,271,390,392,396,397,516,518,522,523,642,644,648,649,768,770,774,775,894,896,900,901,1020,1022,1026,1027,1146,1148,1152,1153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('~/LTM-Encoder-Models/LTM_Structure/data/train_borrow.csv')\n"
     ]
    }
   ],
   "source": [
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('~/LTM-Encoder-Models/LTM_Structure/data/train_borrow.csv')\n",
    "\n",
    "# 将 DataFrame 存储为 RDS 文件\n",
    "pyreadr.write_rds('~/LTM-Encoder-Models/LTM_Structure/data/train_borrow.rds', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37d8438-e151-4d49-a60a-db20b3c552c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1517812/2828609540.py:2: DtypeWarning: Columns (138,140,144,145,264,266,270,271,390,392,396,397,516,518,522,523,642,644,648,649,768,770,774,775,894,896,900,901,1020,1022,1026,1027,1146,1148,1152,1153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('~/LTM-Encoder-Models/LTM_Structure/data/test_borrow.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('~/LTM-Encoder-Models/LTM_Structure/data/test_borrow.csv')\n",
    "\n",
    "# 将 DataFrame 存储为 RDS 文件\n",
    "pyreadr.write_rds('~/LTM-Encoder-Models/LTM_Structure/data/test_borrow.rds', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f97ef-2056-481f-8406-9856115df37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "kaiyang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
