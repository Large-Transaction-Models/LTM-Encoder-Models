{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04e9366-1885-4d8d-b0d0-ede0fd865ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greena12/.conda/envs/greena12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import makedirs\n",
    "from os.path import join, basename\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from args import define_new_main_parser\n",
    "import json\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "from dataset.aave import AaveDataset\n",
    "from dataset.aave_time_static import AaveWithTimePosAndStaticSplitDataset\n",
    "from dataset.aave_time_pos import AaveWithTimePosDataset\n",
    "from dataset.aave_static import AaveWithStaticSplitDataset\n",
    "from models.modules import TabFormerBertLM, TabFormerBertForClassification, TabFormerBertModel, TabStaticFormerBert, \\\n",
    "    TabStaticFormerBertLM, TabStaticFormerBertClassification\n",
    "from misc.utils import ordered_split_dataset, compute_cls_metrics\n",
    "from dataset.datacollator import *\n",
    "from main_aave import main\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71d25b3-2692-45ce-a47e-40eb56554314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 15:34:22,479 - root - INFO - Logging setup completed.\n"
     ]
    }
   ],
   "source": [
    "def setup_logging(output_dir=\"output_aave\", log_file_name='output.log'):\n",
    "    log_dir = join(output_dir, \"logs\")\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    makedirs(log_dir, exist_ok=True)\n",
    "    log_file = join(log_dir, log_file_name)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    fhandler = logging.FileHandler(log_file)\n",
    "    fhandler.setLevel(logging.DEBUG)\n",
    "\n",
    "    chandler = logging.StreamHandler()\n",
    "    chandler.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    chandler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.addHandler(chandler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logging(output_dir=\"output_aave\")\n",
    "\n",
    "\n",
    "logger.info(\"Logging setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22c9d91-648d-4bc4-8f95-2d9acddae6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"/data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet\" \n",
    "dt=\"Aave\"\n",
    "exp_name=\"debug\"\n",
    "time_pos_type=\"regular_position\"\n",
    "fextension= False\n",
    "fname=\"transactions_train_user_market_exoLagged\"\n",
    "val_fname=\"transactions_val\"\n",
    "test_fname=\"transactions_test_user_market_exoLagged\"\n",
    "bs=32\n",
    "field_hs = 64 # hidden state dimension of the transformer (default: 768)\n",
    "seq_len = 25 # length for transaction sliding window\n",
    "stride = 10 # stride for transaction sliding window\n",
    "num_train_epochs=10\n",
    "save_steps=100\n",
    "eval_steps=100\n",
    "external_val=False\n",
    "output_dir=f\"{data}/output/{exp_name}\"\n",
    "checkpoint=None\n",
    "nrows=10000\n",
    "vocab_dir=f\"{data}/vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d9a57b-0dd5-4b64-ac65-5e189091bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_str = f\"--do_train \\\n",
    "    --mlm \\\n",
    "    --pad_seq_first \\\n",
    "    --get_rids \\\n",
    "    --field_ce \\\n",
    "    --lm_type bert \\\n",
    "    --field_hs {field_hs} \\\n",
    "    --data_type {dt} \\\n",
    "    --seq_len {seq_len} \\\n",
    "    --stride {stride} \\\n",
    "    --num_train_epochs {num_train_epochs} \\\n",
    "    --data_root {data}/ \\\n",
    "    --train_batch_size {bs} \\\n",
    "    --eval_batch_size {bs} \\\n",
    "    --save_steps {save_steps} \\\n",
    "    --eval_steps {eval_steps} \\\n",
    "    --data_fname {fname} \\\n",
    "    --data_val_fname {val_fname} \\\n",
    "    --data_test_fname {test_fname} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --time_pos_type {time_pos_type} \\\n",
    "    --vocab_dir {vocab_dir} \\\n",
    "    --nrows {nrows} \\\n",
    "    --vocab_cached \\\n",
    "    --encoder_cached \\\n",
    "    --cached \\\n",
    "    \"\n",
    "   # \n",
    "if fextension:\n",
    "    arg_str += f\"--fextension {fextension} \\\n",
    "    --external_vocab_path {data}/vocab_ob_{fextension}\"\n",
    "else:\n",
    "    arg_str += f\"--external_vocab_path {data}/vocab/vocab_ob\"\n",
    "if external_val:\n",
    "    arg_str += f\"\\\n",
    "    --external_val\"\n",
    "if checkpoint is not None:\n",
    "    arg_str += f\"\\\n",
    "    --checkpoint {checkpoint}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06320fe2-d4bf-41ff-ba54-1223c6f77d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--do_train     --mlm     --pad_seq_first     --get_rids     --field_ce     --lm_type bert     --field_hs 64     --data_type Aave     --seq_len 25     --stride 10     --num_train_epochs 10     --data_root /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/     --train_batch_size 32     --eval_batch_size 32     --save_steps 100     --eval_steps 100     --data_fname transactions_train_user_market_exoLagged     --data_val_fname transactions_val     --data_test_fname transactions_test_user_market_exoLagged     --output_dir /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/output/debug     --time_pos_type regular_position     --vocab_dir /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab     --nrows 10000     --vocab_cached     --encoder_cached     --cached     --external_vocab_path /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab/vocab_ob\n"
     ]
    }
   ],
   "source": [
    "parser = define_new_main_parser(data_type_choices=[\"Aave\", \"Aave_time_pos\", \"Aave_time_static\", \"Aave_static\"])\n",
    "print(arg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9615562a-98c2-4f55-b1ae-38490a5a0e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(jid=1, seed=9, lm_type='bert', flatten=False, field_ce=True, mlm=True, cls_task=False, export_task=False, export_last_only=False, mlm_prob=0.15, freeze=False, data_type='Aave', time_pos_type='regular_position', data_root='/data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/', data_fname='transactions_train_user_market_exoLagged', vocab_file='vocab.nb', user_ids=None, vocab_cached=True, external_encoder_fname='./data/preprocessed/transactionsAave_train.encoder_fit.pkl', external_vocab_fname='./data/vocab_ob', nrows=10000, label_category='last_label', nbatches=None, record_file='experiments', output_dir='/data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/output/debug', pretrained_dir=None, vocab_dir='/data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab', checkpoint=0, do_train=True, do_eval=False, do_prediction=False, save_steps=100, eval_steps=100, num_train_epochs=10, train_batch_size=32, eval_batch_size=32, stride=10, seq_len=25, field_hs=64, skip_user=False, pad_seq_first=True, get_rids=True, long_and_sort=False, user_level_cached=False, external_vocab_path='/data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab/vocab_ob', preload_fextension=None, fextension='', data_val_fname='transactions_val', data_test_fname='transactions_test_user_market_exoLagged', resample_method=None, resample_ratio=10, resample_seed=100, external_val=False, encoder_cached=True, cached=True)\n"
     ]
    }
   ],
   "source": [
    "opts = parser.parse_args(arg_str.split())\n",
    "print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a79b5-cb02-4b9e-9636-2388d9ede926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 15:34:22,540 - dataset.aave_basic - INFO - cached encoded data is read from transactions_train_user_market_exoLagged.encoded.csv\n",
      "2025-01-13 15:34:22,885 - dataset.aave_basic - INFO - read data : (10000, 1011)\n",
      "2025-01-13 15:34:22,898 - dataset.aave_basic - INFO - using cached vocab from /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab/vocab_ob\n",
      "2025-01-13 15:34:22,933 - dataset.aave - INFO - preparing user level data...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 20.19it/s]\n",
      "2025-01-13 15:34:24,372 - dataset.aave - INFO - creating transaction samples with vocab\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:05<00:00,  3.26it/s]\n",
      "2025-01-13 15:34:29,904 - dataset.aave - INFO - ncols: 1008\n",
      "2025-01-13 15:34:29,905 - dataset.aave - INFO - no of samples 1011\n",
      "2025-01-13 15:34:29,993 - main_aave - INFO - vocab size: 11173\n",
      "2025-01-13 15:34:30,007 - main_aave - INFO - dataset size: 1011\n",
      "2025-01-13 15:34:30,095 - dataset.aave_basic - INFO - cached encoded data is read from transactions_train_user_market_exoLagged.encoded.csv\n",
      "2025-01-13 15:34:30,481 - dataset.aave_basic - INFO - read data : (10000, 1011)\n",
      "2025-01-13 15:34:30,482 - dataset.aave_basic - INFO - using cached vocab from /data/IDEA_DeFi_Research/LTM/Data/Lending_Protocols/Aave/V2/Mainnet/vocab/vocab_ob\n",
      "2025-01-13 15:34:30,641 - dataset.aave - INFO - preparing user level data...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 25.45it/s]\n",
      "2025-01-13 15:34:31,857 - dataset.aave - INFO - creating transaction samples with vocab\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:05<00:00,  3.57it/s]\n",
      "2025-01-13 15:34:36,904 - dataset.aave - INFO - ncols: 1008\n",
      "2025-01-13 15:34:36,907 - dataset.aave - INFO - no of samples 1011\n",
      "2025-01-13 15:34:37,001 - main_aave - INFO - test dataset size: 1011\n",
      "2025-01-13 15:34:37,002 - main_aave - INFO - # Using external test dataset, lengths: train [849]  valid [162]  test [1011]\n",
      "2025-01-13 15:34:37,002 - main_aave - INFO - # lengths: train [0.42]  valid [0.08]  test [0.50]\n",
      "/home/greena12/.conda/envs/greena12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "opts.log_dir = join(opts.output_dir, \"logs\")\n",
    "makedirs(opts.output_dir, exist_ok=True)\n",
    "makedirs(opts.log_dir, exist_ok=True)\n",
    "\n",
    "opts.cls_exp_task = opts.cls_task or opts.export_task\n",
    "\n",
    "if opts.data_type in [\"Aave_time_pos\", \"Aave_time_static\"]:\n",
    "    assert opts.time_pos_type == 'time_aware_sin_cos_position'\n",
    "elif opts.data_type in [\"Aave\", \"Aave_static\"]:\n",
    "    assert opts.time_pos_type in ['sin_cos_position', 'regular_position']\n",
    "\n",
    "if (not opts.mlm) and (not opts.cls_exp_task) and opts.lm_type == \"bert\":\n",
    "    raise Exception(\n",
    "        \"Error: Bert needs either '--mlm', '--cls_task' or '--export_task' option. Please re-run with this flag \"\n",
    "        \"included.\")\n",
    "\n",
    "main(opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (greena12)",
   "language": "python",
   "name": "greena12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
